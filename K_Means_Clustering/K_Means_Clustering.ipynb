{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrookehab/Machine_Learning2/blob/main/K_Means_Clustering/K_Means_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-GAXJZHeFAH"
      },
      "source": [
        "# K-means Clustering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shrookehab/Machine_Learning2.git\n",
        "%cd   Machine_Learning2/K_Means_Clustering"
      ],
      "metadata": {
        "id": "VK0vEDwmeH8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtdt9JxpeFAK",
        "outputId": "cd963b49-875c-4de1-b52b-089cf2d1c48f"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'utils'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-bd463ac3b670>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# library written for this exercise providing additional functions for assignment submission, and others\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load_ext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'autoreload'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
          ]
        }
      ],
      "source": [
        "# used for manipulating directory paths\n",
        "import os\n",
        "\n",
        "# Scientific and vector computation for python\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Plotting library\n",
        "from matplotlib import pyplot\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib as mpl\n",
        "\n",
        "from IPython.display import HTML, display, clear_output\n",
        "\n",
        "try:\n",
        "    pyplot.rcParams[\"animation.html\"] = \"jshtml\"\n",
        "except ValueError:\n",
        "    pyplot.rcParams[\"animation.html\"] = \"html5\"\n",
        "\n",
        "# Optimization module in scipy\n",
        "from scipy import optimize\n",
        "\n",
        "# will be used to load MATLAB mat datafile format\n",
        "from scipy.io import loadmat\n",
        "\n",
        "# library written for this exercise providing additional functions for assignment submission, and others\n",
        "import utils\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "\n",
        "# tells matplotlib to embed plots within the notebook\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM02Qm_9eFAP"
      },
      "source": [
        "## 1 K-means Clustering\n",
        "\n",
        "In this exercise, you will implement K-means algorithm and use it for image compression. You will first start on an example 2D dataset that will help you gain an intuition of how the K-means algorithm works. After\n",
        "that, you wil use the K-means algorithm for image compression by reducing the number of colors that occur in an image to only those that are most common in that image.\n",
        "\n",
        "### 1.1 Implementing K-means\n",
        "\n",
        "The K-means algorithm is a method to automatically cluster similar data examples together. Concretely, you are given a training set $\\{x^{(1)} , \\cdots, x^{(m)}\\}$ (where $x^{(i)} \\in \\mathbb{R}^n$), and want to group the data into a few cohesive “clusters”. The intuition behind K-means is an iterative procedure that starts by guessing the initial centroids, and then refines this guess by repeatedly assigning examples to their closest centroids and then recomputing the centroids based on the assignments.\n",
        "\n",
        "The K-means algorithm is as follows:\n",
        "\n",
        "```python\n",
        "centroids = kMeansInitCentroids(X, K)\n",
        "for i in range(iterations):\n",
        "    # Cluster assignment step: Assign each data point to the\n",
        "    # closest centroid. idx[i] corresponds to cˆ(i), the index\n",
        "    # of the centroid assigned to example i\n",
        "    idx = findClosestCentroids(X, centroids)\n",
        "    \n",
        "    # Move centroid step: Compute means based on centroid\n",
        "    # assignments\n",
        "    centroids = computeMeans(X, idx, K)\n",
        "```\n",
        "\n",
        "The inner-loop of the algorithm repeatedly carries out two steps: (1) Assigning each training example $x^{(i)}$ to its closest centroid, and (2) Recomputing the mean of each centroid using the points assigned to it. The K-means algorithm will always converge to some final set of means for the centroids. Note that the converged solution may not always be ideal and depends on the initial setting of the centroids. Therefore, in practice the K-means algorithm is usually run a few times with different random initializations. One way to choose between these different solutions from different random initializations is to choose the one with the lowest cost function value (distortion). You will implement the two phases of the K-means algorithm separately\n",
        "in the next sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REBlQvXueFAR"
      },
      "source": [
        "<a id=\"section1\"></a>\n",
        "#### 1.1.1 Finding closest centroids\n",
        "\n",
        "In the “cluster assignment” phase of the K-means algorithm, the algorithm assigns every training example $x^{(i)}$ to its closest centroid, given the current positions of centroids. Specifically, for every example $i$ we set\n",
        "\n",
        "$$c^{(i)} := j \\quad \\text{that minimizes} \\quad \\lvert\\rvert x^{(i)} - \\mu_j  \\lvert\\rvert^2, $$\n",
        "\n",
        "where $c^{(i)}$ is the index of the centroid that is closest to $x^{(i)}$, and $\\mu_j$ is the position (value) of the $j^{th}$ centroid. Note that $c^{(i)}$ corresponds to `idx[i]` in the starter code.\n",
        "\n",
        "Your task is to complete the code in the function `findClosestCentroids`. This function takes the data matrix `X` and the locations of all centroids inside `centroids` and should output a one-dimensional array `idx` that holds the index (a value in $\\{1, ..., K\\}$, where $K$ is total number of centroids) of the closest centroid to every training example.\n",
        "\n",
        "You can implement this using a loop over every training example and every centroid.\n",
        "<a id=\"findClosestCentroids\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AfBQD17eFAS"
      },
      "outputs": [],
      "source": [
        "def findClosestCentroids(X, centroids):\n",
        "    \"\"\"\n",
        "    Computes the centroid memberships for every example.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array_like\n",
        "        The dataset of size (m, n) where each row is a single example. \n",
        "        That is, we have m examples each of n dimensions.\n",
        "        \n",
        "    centroids : array_like\n",
        "        The k-means centroids of size (K, n). K is the number\n",
        "        of clusters, and n is the the data dimension.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    idx : array_like\n",
        "        A vector of size (m, ) which holds the centroids assignment for each\n",
        "        example (row) in the dataset X.\n",
        "    \n",
        "    Instructions\n",
        "    ------------\n",
        "    Go over every example, find its closest centroid, and store\n",
        "    the index inside `idx` at the appropriate location.\n",
        "    Concretely, idx[i] should contain the index of the centroid\n",
        "    closest to example i. Hence, it should be a value in the \n",
        "    range 0..K-1\n",
        "\n",
        "    Note\n",
        "    ----\n",
        "    You can use a for-loop over the examples to compute this.\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w73fIm7LeFAT"
      },
      "source": [
        "Once you have completed the code in `findClosestCentroids`, the following cell will run your code and you should see the output `[0 2 1]` corresponding to the centroid assignments for the first 3 examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsyQnHojeFAT",
        "outputId": "b6e2d7b7-81f7-43df-9f32-544bdbcfbd27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closest centroids for the first 3 examples:\n",
            "[0 2 1]\n",
            "(the closest centroids should be 0, 2, 1 respectively)\n"
          ]
        }
      ],
      "source": [
        "# Load an example dataset that we will be using\n",
        "data = loadmat(os.path.join('data', 'ex7data2.mat'))\n",
        "X = data['X']\n",
        "\n",
        "# Select an initial set of centroids\n",
        "K = 3   # 3 Centroids\n",
        "initial_centroids = np.array([[3, 3], [6, 2], [8, 5]])\n",
        "\n",
        "# Find the closest centroids for the examples using the initial_centroids\n",
        "idx = findClosestCentroids(X, initial_centroids)\n",
        "\n",
        "print('Closest centroids for the first 3 examples:')\n",
        "print(idx[:3])\n",
        "print('(the closest centroids should be 0, 2, 1 respectively)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvBPcyN0eFAU"
      },
      "source": [
        "<a id=\"section2\"></a>\n",
        "### 1.1.2 Computing centroid means\n",
        "\n",
        "Given assignments of every point to a centroid, the second phase of the algorithm recomputes, for each centroid, the mean of the points that were assigned to it. Specifically, for every centroid $k$ we set\n",
        "\n",
        "$$ \\mu_k := \\frac{1}{\\left| C_k\\right|} \\sum_{i \\in C_k} x^{(i)}$$\n",
        "\n",
        "where $C_k$ is the set of examples that are assigned to centroid $k$. Concretely, if two examples say $x^{(3)}$ and $x^{(5)}$ are assigned to centroid $k = 2$, then you should update $\\mu_2 = \\frac{1}{2} \\left( x^{(3)} + x^{(5)} \\right)$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7dkm-07eFAV"
      },
      "outputs": [],
      "source": [
        "def computeCentroids(X, idx, K):\n",
        "    \"\"\"\n",
        "    Returns the new centroids by computing the means of the data points\n",
        "    assigned to each centroid.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array_like\n",
        "        The datset where each row is a single data point. That is, it \n",
        "        is a matrix of size (m, n) where there are m datapoints each\n",
        "        having n dimensions. \n",
        "    \n",
        "    idx : array_like \n",
        "        A vector (size m) of centroid assignments (i.e. each entry in range [0 ... K-1])\n",
        "        for each example.\n",
        "    \n",
        "    K : int\n",
        "        Number of clusters\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    centroids : array_like\n",
        "        A matrix of size (K, n) where each row is the mean of the data \n",
        "        points assigned to it.\n",
        "    \n",
        "    Instructions\n",
        "    ------------\n",
        "    Go over every centroid and compute mean of all points that\n",
        "    belong to it. Concretely, the row vector centroids[i, :]\n",
        "    should contain the mean of the data points assigned to\n",
        "    cluster i.\n",
        "\n",
        "    Note:\n",
        "    -----\n",
        "    You can use a for-loop over the centroids to compute this.\n",
        "    \"\"\"\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return centroids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2gcsMo0eFAW"
      },
      "source": [
        "Once you have completed the code in `computeCentroids`, the following cell will run your code and output the centroids after the first step of K-means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oepBw1YheFAW",
        "outputId": "a6d561d1-f49b-408b-b72b-73e05aa2af9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Centroids computed after initial finding of closest centroids:\n",
            "[[2.42830111 3.15792418]\n",
            " [5.81350331 2.63365645]\n",
            " [7.11938687 3.6166844 ]]\n",
            "\n",
            "The centroids should be\n",
            "   [ 2.428301 3.157924 ]\n",
            "   [ 5.813503 2.633656 ]\n",
            "   [ 7.119387 3.616684 ]\n"
          ]
        }
      ],
      "source": [
        "# Compute means based on the closest centroids found in the previous part.\n",
        "centroids = computeCentroids(X, idx, K)\n",
        "\n",
        "print('Centroids computed after initial finding of closest centroids:')\n",
        "print(centroids)\n",
        "print('\\nThe centroids should be')\n",
        "print('   [ 2.428301 3.157924 ]')\n",
        "print('   [ 5.813503 2.633656 ]')\n",
        "print('   [ 7.119387 3.616684 ]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr0EblRDeFAX"
      },
      "source": [
        "### 1.2 K-means on example dataset \n",
        "\n",
        "After you have completed the two functions (`findClosestCentroids` and `computeCentroids`), you have all the necessary pieces to run the K-means algorithm. The next cell  will run the K-means algorithm on a toy 2D dataset to help you understand how K-means works. Your functions are called from inside the `runKmeans` function (in this assignment's `utils.py` module). We encourage you to take a look at the function to understand how it works. Notice that the code calls the two functions you implemented in a loop.\n",
        "\n",
        "When you run the next step, the K-means code will produce an animation that steps you through the progress of the algorithm at each iteration. At the end, your figure should look as the one displayed below.\n",
        "\n",
        "![](https://github.com/shrookehab/Machine_Learning2/blob/main/K_Means_Clustering/Figures/kmeans_result.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "mDUN_5tWeFAX"
      },
      "outputs": [],
      "source": [
        "# Load an example dataset\n",
        "data = loadmat(os.path.join('Data', 'ex7data2.mat'))\n",
        "\n",
        "# Settings for running K-Means\n",
        "K = 3\n",
        "max_iters = 10\n",
        "\n",
        "# For consistency, here we set centroids to specific values\n",
        "# but in practice you want to generate them automatically, such as by\n",
        "# settings them to be random examples (as can be seen in\n",
        "# kMeansInitCentroids).\n",
        "initial_centroids = np.array([[3, 3], [6, 2], [8, 5]])\n",
        "\n",
        "\n",
        "# Run K-Means algorithm. The 'true' at the end tells our function to plot\n",
        "# the progress of K-Means\n",
        "centroids, idx, anim = utils.runkMeans(X, initial_centroids,\n",
        "                                       findClosestCentroids, computeCentroids, max_iters, True)\n",
        "anim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zyS7iT3eFAY"
      },
      "source": [
        "### 1.3 Random initialization \n",
        "\n",
        "The initial assignments of centroids for the example dataset in the previous cell were designed so that you will see the same figure as that shown in the cell above. In practice, a\n",
        "good strategy for initializing the centroids is to select random examples from the training set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHjvdKhKeFAY"
      },
      "outputs": [],
      "source": [
        "def kMeansInitCentroids(X, K):\n",
        "    \"\"\"\n",
        "    This function initializes K centroids that are to be used in K-means on the dataset x.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array_like \n",
        "        The dataset of size (m x n).\n",
        "    \n",
        "    K : int\n",
        "        The number of clusters.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    centroids : array_like\n",
        "        Centroids of the clusters. This is a matrix of size (K x n).\n",
        "    \n",
        "    Instructions\n",
        "    ------------\n",
        "    You should set centroids to randomly chosen examples from the dataset X.\n",
        "    \"\"\"\n",
        "   \n",
        "    return centroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xWNg7_5eFAZ"
      },
      "outputs": [],
      "source": [
        "def k_kmeans():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GTHdSjBeFAZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z5CB9OneFAZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "K_Means_Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}